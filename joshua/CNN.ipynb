{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Based on the tflearn CIFAR-10 example at:\n",
    "https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_cifar10.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "from skimage import color, io\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "from tflearn.metrics import Accuracy\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5907 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5907/5907 [00:40<00:00, 145.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "###################################\n",
    "### Import picture files \n",
    "###################################\n",
    "filenames = os.listdir(os.getcwd()+'/data/X_Train')\n",
    "filenames = filter(lambda x: x.endswith('.jpg'), filenames)\n",
    "filenames = map(lambda x: int(x.split('.')[0]), filenames)\n",
    "filenames.sort()\n",
    "filenames = map(lambda x: str(x)+\".jpg\", filenames)\n",
    "\n",
    "n_files = len(filenames)\n",
    "print(n_files)\n",
    "\n",
    "size_image = 64\n",
    "\n",
    "allX = np.zeros((n_files, size_image, size_image, 3), dtype='float64')\n",
    "ally = np.zeros(n_files)\n",
    "count = 0\n",
    "\n",
    "\n",
    "lable_csv = pd.read_csv(\"data/Y_Train.csv\")\n",
    "     \n",
    "for filename in tqdm(filenames):\n",
    "    if filename.endswith('.jpg'):\n",
    "#         sys.stdout.write('Loading %s\\r' % (filename))\n",
    "#         sys.stdout.flush()\n",
    "        img = cv2.imread(os.getcwd()+'/data/X_Train/'+filename)\n",
    "        img = imresize(img, (size_image, size_image, 3))\n",
    "        ally[count] = int(lable_csv[lable_csv[\"Image\"]==filename][\"Label\"])\n",
    "        allX[count] = np.array(img)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.55555\u001b[0m\u001b[0m | time: 54.968s\n",
      "| Adam | epoch: 010 | loss: 0.55555 - Accuracy: 0.7046 -- iter: 5000/5316\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.55640\u001b[0m\u001b[0m | time: 62.841s\n",
      "| Adam | epoch: 010 | loss: 0.55640 - Accuracy: 0.7030 | val_loss: 0.54192 - val_acc: 0.7208 -- iter: 5316/5316\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################################\n",
    "# Prepare train & test samples\n",
    "###################################\n",
    "\n",
    "# test-train split   \n",
    "X, X_test, Y, Y_test = train_test_split(allX, ally, test_size=0.1, random_state=42)\n",
    "\n",
    "# encode the Ys\n",
    "Y = to_categorical(Y, 2)\n",
    "Y_test = to_categorical(Y_test, 2)\n",
    "\n",
    "\n",
    "###################################\n",
    "# Image transformations\n",
    "###################################\n",
    "\n",
    "# normalisation of images\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "# Create extra synthetic training data by flipping & rotating images\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)\n",
    "\n",
    "###################################\n",
    "# Define network architecture\n",
    "###################################\n",
    "\n",
    "# Input is a 32x32 image with 3 color channels (red, green and blue)\n",
    "network = input_data(shape=[None, size_image, size_image, 3],\n",
    "                     data_preprocessing=img_prep,\n",
    "                     data_augmentation=img_aug)\n",
    "\n",
    "# 1: Convolution layer with 32 filters, each 3x3x3\n",
    "conv_1 = conv_2d(network, size_image/2, 3, activation='relu', name='conv_1')\n",
    "\n",
    "# 2: Max pooling layer\n",
    "network = max_pool_2d(conv_1, 2)\n",
    "\n",
    "# 3: Convolution layer with 64 filters\n",
    "conv_2 = conv_2d(network, size_image, 3, activation='relu', name='conv_2')\n",
    "\n",
    "# 4: Convolution layer with 64 filters\n",
    "conv_3 = conv_2d(conv_2, size_image, 3, activation='relu', name='conv_3')\n",
    "\n",
    "# 5: Max pooling layer\n",
    "network = max_pool_2d(conv_3, 2)\n",
    "\n",
    "# 6: Fully-connected 512 node layer\n",
    "network = fully_connected(network, size_image*8, activation='relu')\n",
    "\n",
    "# 7: Dropout layer to combat overfitting\n",
    "network = dropout(network, 0.5)\n",
    "\n",
    "# 8: Fully-connected layer with two outputs\n",
    "network = fully_connected(network, 2, activation='softmax')\n",
    "\n",
    "# Configure how the network will be trained\n",
    "acc = Accuracy(name=\"Accuracy\")\n",
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001, metric=acc)\n",
    "\n",
    "# Wrap the network in a model object\n",
    "model = tflearn.DNN(network, checkpoint_path='model_cat_dog_11.tflearn', max_checkpoints = 3,\n",
    "                    tensorboard_verbose = 3, tensorboard_dir='tmp/tflearn_logs11/')\n",
    "\n",
    "###################################\n",
    "# Train model for 100 epochs\n",
    "###################################\n",
    "model.fit(X, Y, validation_set=(X_test, Y_test), batch_size=500,\n",
    "      n_epoch=10, run_id='model_cat_dog_11', show_metric=True)\n",
    "\n",
    "model.save('model_cat_dog_11_final.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "filenames_test = os.listdir(os.getcwd()+'/data/X_Test')\n",
    "filenames_test = filter(lambda x: x.endswith('.jpg'), filenames_test)\n",
    "filenames_test = map(lambda x: int(x.split('.')[0]), filenames_test)\n",
    "filenames_test.sort()\n",
    "filenames_test = map(lambda x: str(x)+\".jpg\", filenames_test)\n",
    "\n",
    "resultX = np.zeros((len(filenames_test), size_image, size_image, 3), dtype='float64')\n",
    "resultCount = 0\n",
    "\n",
    "for filename in filenames_test:\n",
    "    if filename.endswith('.jpg'):\n",
    "#         print(filename)\n",
    "        img = cv2.imread(\"data/X_Test/\"+filename)\n",
    "        img = imresize(img, (size_image, size_image, 3))\n",
    "        resultX[resultCount] = np.array(img)\n",
    "        resultCount += 1\n",
    "result =  model.predict(resultX)\n",
    "# print(resultX)\n",
    "#         writer.writerow( (filename, result) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"result11.csv\", 'wt')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow( ('Image', 'Label') )\n",
    "\n",
    "for i in xrange(len(filenames_test)):\n",
    "    writer.writerow((filenames_test[i], np.argmax(result[i])))\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
